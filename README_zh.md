# Â§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ÂøÉÁêÜÂÅ•Â∫∑È¢ÜÂüüÁöÑÂ∫îÁî®


> üîó [English Version](README.md)

- [Áé∞ÊúâÁªºËø∞ ](#Áé∞ÊúâÁªºËø∞ )
- [Â§ßÊ®°ÂûãÂèØÂ∫îÁî®Âú®ÂøÉÁêÜÂÅ•Â∫∑È¢ÜÂüüÁöÑÂÆûËØÅ‰æùÊçÆ ](#Â§ßÊ®°ÂûãÂèØÂ∫îÁî®Âú®ÂøÉÁêÜÂÅ•Â∫∑È¢ÜÂüüÁöÑÂÆûËØÅ‰æùÊçÆ )
- [Â§ßÊ®°ÂûãÂú®ÂøÉÁêÜÂÅ•Â∫∑‰∏¥Â∫äÂú∫ÊôØÁöÑÂ∫îÁî®](#Â§ßÊ®°ÂûãÂú®ÂøÉÁêÜÂÅ•Â∫∑‰∏¥Â∫äÂú∫ÊôØÁöÑÂ∫îÁî®)
- [ÂøÉÁêÜÂÅ•Â∫∑È¢ÜÂüüÂ§ßÊ®°ÂûãÊäÄÊúØÂèëÂ±ï](#ÂøÉÁêÜÂÅ•Â∫∑È¢ÜÂüüÂ§ßÊ®°ÂûãÊäÄÊúØÂèëÂ±ï)
- [Áé∞Â≠òÊåëÊàò](#Áé∞Â≠òÊåëÊàò)

# Áé∞ÊúâÁªºËø∞
[1]Global, regional, and national burden of 12 mental disorders in 204 countries and territories,1990‚Äì2019: a systematic analysis for the global burden of disease study 2019[J]. The Lancet Psychiatry, 2022, 9(2): 137-150.

[2]HENGLE A, KULKARNI A, PATANKAR S D, et al. Still not quite there! evaluating large language models for comorbid mental health diagnosis[C/OL]//AL-ONAIZAN Y, BANSAL M, CHEN Y N. Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 2024: 16698-16721.

[3]XIAO M, XIE Q, KUANG Z, et al. HealMe: Harnessing cognitive reframing in large language models for psychotherapy[C/OL]//KU L W, MARTINS A, SRIKUMAR V. Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2024: 1707-1725.

[4]FARQUHAR S, KOSSEN J, KUHN L, et al. Detecting hallucinations in large language models using semantic entropy[J]. Nature, 2024, 630(8017): 625-630.

[5]NING Y, TEIXAYAVONG S, SHANG Y, et al. Generative artificial intelligence and ethical considerations in health care: a scoping review and ethics checklist[J]. The Lancet Digital Health, 2024, 6(11): e848-e856.

[6]GUO Z, LAI A, THYGESEN J H, et al. Large language models for mental health applications: systematic review[J]. JMIR mental health, 2024, 11(1): e57400.

[7]HUA Y, NA H, LI Z, et al. A scoping review of large language models for generative tasks in mental health care[J]. npj Digital Medicine, 2025, 8(1): 230.

[8]OMAR M, SOFFER S, CHARNEY A W, et al. Applications of large language models in psychiatry: a systematic review[J]. Frontiers in psychiatry, 2024, 15: 1422807.

[9]LAWRENCE H R, SCHNEIDER R A, RUBIN S B, et al. The opportunities and risks of large language models in mental health[J]. JMIR Mental Health, 2024, 11(1): e59479..

[10] LINARDON J, MESSER M, ANDERSON C, et al. Role of large language models in mental health research: an international survey of researchers‚Äôpractices and perspectives[J]. BMJ Mental Health, 2025, 28(1): e301787.

[11]YUAN A, GARCIA COLATO E, PESCOSOLIDO B, et al. Improving workplace well-being in modern organizations: A review of large language model-based mental health chatbots[J]. ACM Transactions on Management Information Systems, 2025, 16(1): 1-26.

[12]NA H, HUA Y, WANG Z, et al. A survey of large language models in psychotherapy: Current landscape and future directions[J]. arXiv preprint arXiv:2502.11095, 2025.

# Â§ßÊ®°ÂûãÂèØÂ∫îÁî®Âú®ÂøÉÁêÜÂÅ•Â∫∑È¢ÜÂüüÁöÑÂÆûËØÅ‰æùÊçÆ

[13]JIANG Y, SHEN Q, LAI S, et al. Copiloting diagnosis of autism in real clinical scenarios via llms[EB/OL]. 2024. https://arxiv.org/abs/2410.05684. [2025-10-25]

[14] GALATZER-LEVY I, MCDUFF D, MALGAROLI M. The capability of large language models to measure and differentiate psychiatric conditions through O-Shot learning[J]. Biological Psychiatry, 2025, 97(9): S62.

[15]LAN X, CHENG Y, SHENG L, et al. Depression detection on social media with large language models[EB/OL]. 2024. https://arxiv.org/abs/2403.10750. [2025-10-25]

[16]JIANG H, ZHANG X, CAO X, et al. PersonaLLM: Investigating the ability of large language models to express personality traits[C/OL]//DUH K, GOMEZ H, BETHARD S. Findings of the Association for Computational Linguistics: NAACL 2024. 2024: 3605-3627.

[17]LI X, LI Y, QIU L, et al. Evaluating psychological safety of large language models[C/OL]// AL-ONAIZAN Y, BANSAL M, CHEN Y N. Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 2024: 1826-1843.

[18]HUANG J T, JIAO W, LAM M H, et al. On the reliability of psychological scales on large language models[C/OL]//AL-ONAIZAN Y, BANSAL M, CHEN Y N. Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 2024: 6152-6173.

[19]TSE HUANG J, WANG W, LI E J, et al. On the humanity of conversational AI: Evaluating the psychological portrayal of LLMs[C/OL]//The Twelfth International Conference on Learning Representations. 2024.

[20]SCHAAFF K, REINIG C, SCHLIPPE T. Exploring chatgpt‚Äôs empathic abilities[C]//2023 11th international conference on affective computing and intelligent interaction (ACII). 2023: 1-8.

[21]ELYOSEPH Z, HADAR-SHOVAL D, ASRAF K, et al. Chatgpt outperforms humans in emotional awareness evaluations[J/OL]. Frontiers in Psychology, 2023, Volume 14 - 2023.

[22]HUANG J T, LAM M H, LI E J, et al. Apathetic or empathetic? evaluating llms'emotional alignments with humans[C/OL]//GLOBERSON A, MACKEY L, BELGRAVE D, et al. Advances in Neural Information Processing Systems: volume 37. 2024: 97053-97087.

[23]PATEL S C, FAN J. Identification and description of emotions by current large language models[J/OL]. bioRxiv, 2023.

[24]SCHLEGEL K, SOMMER N R, MORTILLARO M. Large language models are proficient in solving and creating emotional intelligence tests[J]. Communications Psychology, 2025, 3(1): 80.

[25]ZHOU J, CHEN Z, WAN D, et al. CharacterGLM: Customizing social characters with large language models[C/OL]//DERNONCOURT F, PREO≈¢IUC-PIETRO D, SHIMORINA A. Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Industry Track. 2024: 1457-1476.

[26] LI W, LIU J, LIU A, et al. BIG5-CHAT: Shaping LLM personalities through training on human-grounded data[C/OL]//CHE W, NABENDE J, SHUTOVA E, et al. Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2025: 20434-20471.

[27]LI T, DOU S, LV C, et al. Tailoring personality traits in large language models via unsupervisedly built personalized lexicons[EB/OL]. 2024. https://arxiv.org/abs/2310.16582.

[28]TU Q, CHEN C, LI J, et al. Characterchat: Learning towards conversational ai with personalized social support[EB/OL]. 2023. https://arxiv.org/abs/2308.10278. [2025-10-25]

[29]JIANG G, XU M, ZHU S C, et al. Evaluating and inducing personality in pre-trained language models[C]//NIPS ‚Äô23: Proceedings of the 37th International Conference on Neural Information Processing Systems. 2023.

[30]JAIN N, WU Z, VILLALOBOS C E M, et al. From text to emoji: How PEFT-driven personality manipulation unleashes the emoji potential in LLMs[C/OL]//CHIRUZZO L, RITTER A, WANG L. Findings of the Association for Computational Linguistics: NAACL 2025. 2025: 4687-4723.

# Â§ßÊ®°ÂûãÂú®ÂøÉÁêÜÂÅ•Â∫∑‰∏¥Â∫äÂú∫ÊôØÁöÑÂ∫îÁî®

[31]LHO S K, PARK S C, LEE H, et al. Large language models and text embeddings for detecting depression and suicide in patient narratives[J/OL]. JAMA Network Open, 2025, 8(5): e2511922- e2511922.

[32]XU Y, FANG Z, LIN W, et al. Evaluation of large language models on mental health: from knowledge test to illness diagnosis[J/OL]. Frontiers in Psychiatry, 2025, Volume 16 - 2025.

[33]TU S, POWERS A, MERRILL N, et al. Automating PTSD diagnostics in clinical interviews: Leveraging large language models for trauma assessments[C/OL]//KAWAHARA T, DEMBERG V, ULTES S, et al. Proceedings of the 25th Annual Meeting of the Special Interest Group on Discourse and Dialogue. 2024: 644-663.

[34]QI H, FU G, LI J, et al. Supervised learning and large language model benchmarks on mental health datasets: Cognitive distortions and suicidal risks in chinese social media[J/OL]. Bioengineering, 2025, 12(8).

[35]HOANG V, ROGERS E, ROSS R. How can client motivational language inform psychotherapy agents?[C/OL]//YATES A, DESMET B, PRUD‚ÄôHOMMEAUX E, et al. Proceedings of the 9th Workshop on Computational Linguistics and Clinical Psychology (CLPsych 2024). 2024: 23-40.

[36]YANG Q, WANG Z, CHEN H, et al. PsychoGAT: A novel psychological measurement paradigm through interactive fiction games with LLM agents[C/OL]//KU L W, MARTINS A, SRIKUMAR V. Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2024: 14470-14505.

[37]SHARMA A, RUSHTON K, LIN I, et al. Cognitive reframing of negative thoughts through human-language model interaction[C/OL]//ROGERS A, BOYD-GRABER J, OKAZAKI N. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023: 9977-10000.

[38]HEINZ M V, MACKIN D M, TRUDEAU B M, et al. Randomized trial of a generative ai chatbot for mental health treatment[J/OL]. NEJM AI, 2025, 2(4): AIoa2400802.

[39]WANG Y, WANG Y, XIAO Y, et al. Evaluating an llm-powered chatbot for cognitive restructuring: Insights from mental health professionals[EB/OL]. 2025. https://arxiv.org/abs/2501.1 5599. [2025-10-25]

[40]HU H, ZHOU Y, SI J, et al. Beyond empathy: Integrating diagnostic and therapeutic reasoning with large language models for mental health counseling[EB/OL]. 2025. https://arxiv.org/abs/2505.15715. [2025-10-25]

[41]KIM T, BAE S, KIM H A, et al. Mindfuldiary: Harnessing large language model to support psychiatric patients‚Äô journaling[C/OL]//CHI ‚Äô24: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems. 2024.

[42]HABICHT J, DINA L M, MCFADYEN J, et al. Generative ai-enabled therapy support tool for improved clinical outcomes and patient engagement in group therapy: Real-world observational study[J]. Journal of medical Internet research, 2025, 27: e60435.

[43]MADDELA M, UNG M, XU J, et al. Training models to generate, recognize, and reframe unhelpful thoughts[C/OL]//ROGERS A, BOYD-GRABER J, OKAZAKI N. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023: 13641-13660.

[44]LIN S, WANG Y, DONG J, et al. Detection and positive reconstruction of cognitive distortion sentences: Mandarin dataset and evaluation[C/OL]//KU L W, MARTINS A, SRIKUMAR V. Findings of the Association for Computational Linguistics: ACL 2024. 2024: 6686-6701.

[45]CABRERA LOZOYA D, CONWAY M, SEBASTIANO DE DURO E, et al. Leveraging large language models for simulated psychotherapy client interactions: Development and usability study of client101[J/OL]. JMIR Med Educ, 2025, 11: e68056.

# ÂøÉÁêÜÂÅ•Â∫∑È¢ÜÂüüÂ§ßÊ®°ÂûãÊäÄÊúØÂèëÂ±ï

[46]LIU S, ZHENG C, DEMASI O, et al. Towards emotional support dialog systems[C/OL]// ZONG C, XIA F, LI W, et al. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021: 3469-348.

[47]CHEN Y, XING X, LIN J, et al. SoulChat: Improving LLMs‚Äô empathy, listening, and comfort abilities through fine-tuning with multi-turn empathy conversations[C/OL]//BOUAMOR H, PINO J, BALI K. Findings of the Association for Computational Linguistics: EMNLP 2023. 2023: 1170-1183.

[48] ZHANG C, LI R, TAN M, et al. CPsyCoun: A report-based multi-turn dialogue reconstruction and evaluation framework for Chinese psychological counseling[C/OL]//KU L W, MARTINS A, SRIKUMAR V. Findings of the Association for Computational Linguistics: ACL 2024. 2024: 13947-13966.

[49] XIE H, CHEN Y, XING X, et al. PsyDT: Using LLMs to construct the digital twin of psychological counselor with personalized counseling style for psychological counseling[C/OL]// CHE W, NABENDE J, SHUTOVA E, et al. Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2025: 1081-111.

[50]ZHENG Z, LIAO L, DENG Y, et al. Self-chats from large language models make small emotional support chatbot better[C/OL]//KU L W, MARTINS A, SRIKUMAR V. Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2024: 11325-11345.

[51]YE J, XIANG L, ZHANG Y, et al. SweetieChat: A strategy-enhanced role-playing framework for diverse scenarios handling emotional support agent[C/OL]//RAMBOW O, WANNER L, APIDIANAKI M, et al. Proceedings of the 31st International Conference on Computational Linguistics. 2025: 4646-4669.

[52]WANG J, HUANG Y, LIU Z, et al. Stampsy: Towards spatiotemporal-aware mixed-type dialogues for psychological counseling[J/OL]. Proceedings of the AAAI Conference on Artificial Intelligence, 2025, 39(24): 25371-25379.

[53]HU J, DONG T, LUO G, et al. Psycollm: Enhancing llm for psychological understanding and evaluation[J/OL]. IEEE Transactions on Computational Social Systems, 2025, 12(2): 539-551.

[54]TU Q, LI Y, CUI J, et al. MISC: A mixed strategy-aware model integrating COMET for emotional support conversation[C/OL]//MURESAN S, NAKOV P, VILLAVICENCIO A. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2022: 308-319. [2025-10-25]

[55]ZHOU J, ZHENG C, WANG B, et al. CASE: Aligning coarse-to-fine cognition and affection for empathetic response generation[C/OL]//ROGERS A, BOYD-GRABER J, OKAZAKI N. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023: 8223-8237.

[56]HU Y, TAN M, ZHANG C, et al. Aptness: Incorporating appraisal theory and emotion support strategies for empathetic response generation[C/OL]//CIKM ‚Äô24: Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. 2024: 900‚Äì909.

[57]QIAN Y, ZHANG W, LIU T. Harnessing the power of large language models for empathetic response generation: Empirical investigations and improvements[C/OL]//BOUAMOR H, PINO J, BALI K. Findings of the Association for Computational Linguistics: EMNLP 2023. 2023: 6516-6528.

[58]YANG D, ZHU J, WU H, et al. Cascadercg: Retrieval-augmented generation for enhancing professionalism and knowledgeability in online mental health support[C/OL]//WWW ‚Äô25: Companion Proceedings of the ACM on Web Conference 2025. 2025: 1465‚Äì1469.

[59]LI R, TAN M, WONG D F, et al. CoEvol: Constructing better responses for instruction fine-tuning through multi-agent cooperation[C/OL]//AL-ONAIZAN Y, BANSAL M, CHEN Y N. Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 2024: 4703-4721.

[60]XIAO M, YE M, LIU B, et al. A retrieval-augmented multi-agent framework for psychiatry diagnosis[J]. arXiv preprint arXiv:2506.03750, 2025. [2025-10-25]

[61]XU A, YANG D, LI R, et al. Autocbt: An autonomous multi-agent framework for cognitive behavioral therapy in psychological counseling[J]. arXiv preprint arXiv:2501.09426, 2025. [2025-10-25]

[62]WANG M, WANG P, WU L, et al. AnnaAgent: Dynamic evolution agent system with multisession memory for realistic seeker simulation[C/OL]//CHE W, NABENDE J, SHUTOVA E, et al. Findings of the Association for Computational Linguistics: ACL 2025. 2025: 23221-23235.

[63]QI Z, KANEKO T, TAKAMIZO K, et al. Kokorochat: A japanese psychological counseling dialogue dataset collected via role-playing by trained counselors[J]. arXiv preprint arXiv:2506.01357, 2025. [2025-10-25]

[64]KIM H, LEE S, CHO Y, et al. Kmi: A dataset of korean motivational interviewing dialogues for psychotherapy[J]. arXiv preprint arXiv:2502.05651, 2025. [2025-10-25]

[65]LIU C C, ARNAOUT H, KOVAƒçIƒá N, et al. Tailored emotional llm-supporter: Enhancing cultural sensitivity[EB/OL]. 2025. https://arxiv.org/abs/2508.07902. [2025-10-25]

[66]JOHN O P, DONAHUE E M, KENTLE R L. Big five inventory[J]. Journal of personality and social psychology, 1991.

[67]BAGBY R, PARKER J D, TAYLOR G J. The twenty-item toronto alexithymia scale‚Äîi. item selection and cross-validation of the factor structure[J/OL]. Journal of Psychosomatic Research, 1994, 38(1): 23-32.

[68]BARON-COHEN S, WHEELWRIGHT S. The empathy quotient: an investigation of adults with asperger syndrome or high functioning autism, and normal sex differences[J]. Journal of autism and developmental disorders, 2004, 34: 163-75.

[69] HOJAT M, GONNELLA J S, NASCA T J, et al. The jefferson scale of physician empathy: further psychometric data and differences by gender and specialty at item level[J]. Academic medicine : journal of the Association of American Medical Colleges, 2002, 77: S58-60.

[70]MERCER S W, MAXWELL M, HEANEY D, et al. The consultation and relational empathy(care) measure: development and preliminary validation and reliability of an empathy-based consultation process measure[J]. Family practice, 2004, 21: 699-705.

[71]DAVIS M H. Measuring individual differences in empathy: Evidence for a multidimensional approach[J]. Journal of Personality and Social Psychology, 1983, 44(1): 113-126.

[72]ROTER D, LARSON S. The roter interaction analysis system (rias): utility and flexibility for analysis of medical interactions[J]. Patient education and counseling, 2002, 46: 243-51.

[73]KRUPAT E, FRANKEL R, STEIN T, et al. The four habits coding scheme: validation of an instrument to assess clinicians‚Äô communication behavior[J]. Patient education and counseling, 2006, 62: 38-45.

[74]JIN H, CHEN S, DILIXIATI D, et al. Psyeval: A suite of mental health related tasks for evaluating large language models[EB/OL]. 2024. https://arxiv.org/abs/2311.09189. [2025-10-25]

[75]ZHANG J, HE H, SONG N, et al. Conceptpsy:a benchmark suite with conceptual comprehensiveness in psychology[EB/OL]. 2024. https://arxiv.org/abs/2311.09861. [2025-10-25]

[76]ZHAO J, ZHU J, TAN M, et al. CPsyExam: A Chinese benchmark for evaluating psychology using examinations[C/OL]//RAMBOW O, WANNER L, APIDIANAKI M, et al. Proceedings of the 31st International Conference on Computational Linguistics. 2025: 11248-11260.

[77]WANG X, JIANG L, HERNANDEZ-ORALLO J, et al. Evaluating general-purpose ai with psychometrics[EB/OL]. 2023. https://arxiv.org/abs/2310.16379. [2025-10-25]

[78]TAM T Y C, SIVARAJKUMAR S, KAPOOR S, et al. A framework for human evaluation of large language models in healthcare derived from literature review[J]. npj Digital Medicine, 2024, 7(1): 258.

[79]LIU J M, LI D, CAO H, et al. Chatcounselor: A large language models for mental health support[EB/OL]. 2023. https://arxiv.org/abs/2309.15461. [2025-10-25]

[80]WANG X, XIAO Y, HUANG J T, et al. InCharacter: Evaluating personality fidelity in role-playing agents through psychological interviews[C/OL]//KU L W, MARTINS A, SRIKUMAR V. Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2024: 1840-1873.

[81]EBERHARDT S T, VEHLEN A, SCHAFFRATH J, et al. Development and validation of large language model rating scales for automatically transcribed psychological therapy sessions[J]. Scientific Reports, 2025, 15(1): 29541.

[82]SZYMANSKI A, ZIEMS N, EICHER-MILLER H A, et al. Limitations of the llm-as-a-judge approach for evaluating llm outputs in expert knowledge tasks[C/OL]//IUI ‚Äô25: Proceedings of the 30th International Conference on Intelligent User Interfaces. 2025: 952‚Äì966.


# Áé∞Â≠òÊåëÊàò

[83]ERIKSEN A V, M√ñLLER S, RYG J. Use of gpt-4 to diagnose complex clinical cases[J]. Nejm Ai, 2024, 1(1): AIp2300031.

[84]GOH E, GALLO R, HOM J, et al. Large language model influence on diagnostic reasoning: a randomized clinical trial[J]. JAMA network open, 2024, 7(10): e2440969-e2440969.

[85]OBRADOVICH N, KHALSA S S, KHAN W U, et al. Opportunities and risks of large language models in psychiatry[J]. NPP‚ÄîDigital Psychiatry and Neuroscience, 2024, 2(1): 8.

[86]GABRIEL S, PURI I, XU X, et al. Can ai relate: Testing large language model response for mental health support[EB/OL]. arXiv preprint arXiv:2405.12021, 2024. [2025-10-25]

[87]LI H, ZHANG R, LEE Y C, et al. Systematic review and meta-analysis of ai-based conversational agents for promoting mental health and well-being[J]. NPJ Digital Medicine, 2023, 6(1): 236.

[88]STADE E C, STIRMAN S W, UNGAR L H, et al. Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation[J]. NPJ Mental Health Research, 2024, 3(1): 12.

[89]ARORA A, ALDERMAN J E, PALMER J, et al. The value of standards for health datasets in artificial intelligence-based applications[J]. Nature medicine, 2023, 29(11): 2929-2938.

[90]ZHU J, TAN M, YANG M, et al. Collectivesft: Scaling large language models for chinese medical benchmark with collective instructions in healthcare[C]//International Conference on Social Robotics. 2024: 51-60.

[91]ASGARI E, MONTA√ëA-BROWN N, DUBOIS M, et al. A framework to assess clinical safety and hallucination rates of llms for medical text summarisation[J]. npj Digital Medicine, 2025, 8(1): 274.

[92]HAGER P, JUNGMANN F, HOLLAND R, et al. Evaluation and mitigation of the limitations of large language models in clinical decision-making[J]. Nature medicine, 2024, 30(9): 2613-2622.

[93]FARQUHAR S, KOSSEN J, KUHN L, et al. Detecting hallucinations in large language models using semantic entropy[J]. Nature, 2024, 630(8017): 625-630.

[94]ROUSTAN D, BASTARDOT F, et al. The clinicians‚Äôguide to large language models: A general perspective with a focus on hallucinations[J]. Interactive journal of medical research, 2025, 14(1): e59823.

[95]ZHU J, XU A, TAN M, et al. Xinhai@ clpsych 2024 shared task: Prompting healthcare-oriented llms for evidence highlighting in posts with suicide risk[C]//Proceedings of the 9th Workshop on Computational Linguistics and Clinical Psychology (CLPsych 2024). 2024: 238-246.

